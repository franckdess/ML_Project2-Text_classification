{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from tokenizer import tokenizer\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR, LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "tweet_pos, tweet_neg, tweet_test = import_data(full = False)\n",
    "\n",
    "# Construct train set\n",
    "tweet_pos['pred'] = 1\n",
    "tweet_neg['pred'] = 0\n",
    "tweet_pos.columns = ['tweet', 'pred']\n",
    "tweet_neg.columns = ['tweet', 'pred']\n",
    "all_tweets = tweet_neg.append(tweet_pos)\n",
    "tweet_TR = all_tweets.reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "# Construct test set\n",
    "tweet_clean = clean_data(tweet_test.values)\n",
    "np.reshape(tweet_clean, (10000,))\n",
    "tweet_TE = tweet_clean.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import stopwords\n",
    "stopw = pd.read_csv('data/stopwords/twitter-stopwords-final.txt').values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', stop_words = stopw, tokenizer=tokenize, ngram_range=(1,4))\n",
    "X = vectorizer.fit_transform(tweet_TR.values[:, 0])\n",
    "Y = tweet_TR.values[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a standard classifier\n",
    "clf = SVC(kernel='linear', cache_size=2000, gamma='auto')\n",
    "\n",
    "clf.fit(x_train[:80000, :], y_train[:80000])\n",
    "# Compute the predicitions of x_test\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.841675"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the standard model's accuracy (SVC) using 80'000 samples - half of the small dataset\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8351"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the standard model's accuracy (SVC) using 50'000 samples\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.815075"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the standard model's accuracy (SVC) using 20'000 samples.\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find out the best parameters using small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def param_selection(X, Y, nfolds, param_grid, classifier):\n",
    "    \"\"\" Given the features and the predicitons, the number of cross validation,\n",
    "        the parameter grid and the classifier, return the best parameters.\"\"\"\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv = nfolds)\n",
    "    grid_search.fit(X, Y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the list of parameters to test\n",
    "losses = ['hinge', 'squared_hinge']\n",
    "tols = [1e-5, 1e-4, 1e-3]\n",
    "Cs = [0.1, 1, 10]\n",
    "random_state = [42]\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'loss': losses, 'tol': tols, 'C': Cs, 'random_state': random_state}\n",
    "\n",
    "# Find the best parameters\n",
    "best_parameters = param_selection(x_train, y_train, 5, param_grid, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'loss': 'hinge', 'random_state': 42, 'tol': 1e-05}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best parameters\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the best parameters\n",
    "tol_opt = best_parameters['tol']\n",
    "C_opt = best_parameters['C']\n",
    "loss_opt = best_parameters['loss']\n",
    "\n",
    "# Create a new classifier with the optimal parameters\n",
    "clf_optimal = LinearSVC(C=C_opt, tol=tol_opt, loss=loss_opt, random_state=42)\n",
    "\n",
    "model = clf_optimal.fit(x_train, y_train)\n",
    "\n",
    "# Compute the predictions of x_test\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.852025"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the optimal model's accuracy\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the predictions using optimal parameters on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "tweet_pos, tweet_neg, tweet_test = import_data(full = True)\n",
    "\n",
    "# Construct train set\n",
    "tweet_pos['pred'] = 1\n",
    "tweet_neg['pred'] = 0\n",
    "tweet_pos.columns = ['tweet', 'pred']\n",
    "tweet_neg.columns = ['tweet', 'pred']\n",
    "all_tweets = tweet_neg.append(tweet_pos)\n",
    "tweet_TR = all_tweets.reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "# Construct test set\n",
    "tweet_clean = clean_data(tweet_test.values)\n",
    "np.reshape(tweet_clean, (10000,))\n",
    "tweet_TE = tweet_clean.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', stop_words = stopw, tokenizer=tokenize, ngram_range=(1,4))\n",
    "X = vectorizer.fit_transform(tweet_TR.values[:, 0])\n",
    "Y = tweet_TR.values[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franckdessimoz/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model_optimal = clf_optimal.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.876936"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_optimal.predict(x_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the real predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TE = vectorizer.transform(tweet_TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_TE = model_optimal.predict(X_TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build_submission(y_pred_TE, '14_linearSVC_optimal_3_updated_tokenizer')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
