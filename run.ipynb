{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from tokenizer import tokenizer\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocess the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the preprocessing of the data by importing the datasets. We then created a dataframe containing all train tweet with the sentiment prediction associated, which is 0 for negative tweet and 1 for positive tweet. Then we created a TfidfVectorizer with tuned toknizer, stopwords, ngram_range and df_min. We applied the vectorizer to the tweets and splitted the vectorized train tweets into a train set and a test set, in order to compute accuracy localy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the small dataset\n",
    "tweet_pos, tweet_neg, tweet_test = import_data(full = False)\n",
    "\n",
    "# Construct train and test set\n",
    "tweet_TR = construct_train_set(tweet_pos, tweet_neg)\n",
    "tweet_TE = construct_test_set(tweet_test)\n",
    "\n",
    "# Import stopwords\n",
    "stopw = pd.read_csv('data/twitter-stopwords.txt').values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word', stop_words=stopw, tokenizer=tokenize, ngram_range=(1,4), min_df=10)\n",
    "\n",
    "# Apply TfidfVectorizer to the small train set\n",
    "X = vectorizer.fit_transform(tweet_TR.values[:, 0])\n",
    "Y = tweet_TR.values[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the small train set for local accuracy computation\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define the standard classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a LinearSVC classifier and computed the accuracy with the classifier's standard parameters on the small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a standard LinearSVC classifier\n",
    "clf = LinearSVC(random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "# Compute the predicitions of x_test\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the standard classifier's accuracy (LinearSVC)\n",
    "print('Dataset: Small\\nClassifier: LinearSVC\\nParameters: Standard\\nAccuracy: {:2.2%}'.format(accuracy_score(y_pred, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Find out the best parameters using the small dataset and Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a grid search using 5-fold crossvalidation in order to find the parameters that optimize the classifier. Note that we only choose 3 parameters to test for each parameters, in order to keep the computation runable on our computers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the list of parameters to test\n",
    "losses = ['hinge', 'squared_hinge']\n",
    "tols = [1e-5, 1e-4, 1e-3]\n",
    "Cs = [0.1, 1, 10]\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'loss': losses, 'tol': tols, 'C': Cs}\n",
    "\n",
    "# Find the best parameters\n",
    "best_parameters = param_selection(x_train, y_train, 5, param_grid, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the best parameters\n",
    "loss_opt = best_parameters['loss']\n",
    "tol_opt = best_parameters['tol']\n",
    "C_opt = best_parameters['C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print best parameters\n",
    "print('Best parameters:\\nloss: {}\\ntol: {}\\nC: {}'.format(loss_opt, tol_opt, C_opt))                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a new LinearSVC classifier with the optimal parameters obtained with the grid search. After that we compute the new accuracy of the optimal classifier on the small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a new LinearSVC classifier with the optimal parameters\n",
    "clf_optimal = LinearSVC(C=C_opt, tol=tol_opt, loss=loss_opt, random_state=42)\n",
    "model_optimal = clf_optimal.fit(x_train, y_train)\n",
    "\n",
    "# Compute the predictions of x_test\n",
    "y_pred_optimal = model_optimal.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the optimal classifier's accuracy (LinearSVC)\n",
    "print('Dataset: Small\\nClassifier: LinearSVC\\nParameters: Optimal\\nAccuracy: {:2.2%}'.format(accuracy_score(y_pred_optimal, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Get the predictions using optimal classifier on full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the full dataset, create the tweets' vector using the same TfidfVectorizer as above, and run the optimal LinearSVC classifier on the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the full dataset\n",
    "tweet_pos_full, tweet_neg_full, tweet_test_full = import_data(full = True)\n",
    "\n",
    "# Construct train and test set\n",
    "tweet_TR_full = construct_train_set(tweet_pos_full, tweet_neg_full)\n",
    "tweet_TE_full = construct_test_set(tweet_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply TfidfVectorizer to the full train set\n",
    "X_full = vectorizer.fit_transform(tweet_TR_full.values[:, 0])\n",
    "Y_full = tweet_TR_full.values[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the full train set for local accuracy computation\n",
    "x_train_full, x_test_full, y_train_full, y_test_full = train_test_split(X_full, Y_full, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the optimal classifier to the full dataset\n",
    "model_optimal_full = clf_optimal.fit(x_train_full, y_train_full)\n",
    "\n",
    "# Compute the predictions of x_test\n",
    "y_pred_full = model_optimal_full.predict(x_test_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the optimal classifier's accuracy (LinearSVC)\n",
    "print('Dataset: Full\\nClassifier: LinearSVC\\nParameters: Optimal\\nAccuracy: {:2.2%}'.format(accuracy_score(y_pred_full, y_test_full)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Output the final predicitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We output the final predictions to be submitted on CrowdAi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply TfidfVectorizer to the test set\n",
    "X_TE = vectorizer.transform(tweet_TE)\n",
    "\n",
    "# Apply the optimal classifier to the test set\n",
    "y_pred_TE = model_optimal.predict(X_TE)\n",
    "\n",
    "# Build submission to be submitted on CrowdAi\n",
    "build_submission(y_pred_TE, 'final_submission_ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
