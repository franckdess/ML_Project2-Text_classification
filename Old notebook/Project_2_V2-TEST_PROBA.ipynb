{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from tokenizer import tokenizer\n",
    "\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR, LinearSVC, SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "tweet_pos, tweet_neg, tweet_test = import_data(full = False)\n",
    "\n",
    "# Construct train set\n",
    "tweet_pos['pred'] = 1\n",
    "tweet_neg['pred'] = 0\n",
    "tweet_pos.columns = ['tweet', 'pred']\n",
    "tweet_neg.columns = ['tweet', 'pred']\n",
    "all_tweets = tweet_neg.append(tweet_pos)\n",
    "tweet_TR = all_tweets.reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "# Construct test set\n",
    "tweet_clean = clean_data(tweet_test.values)\n",
    "np.reshape(tweet_clean, (10000,))\n",
    "tweet_TE = tweet_clean.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import stopwords\n",
    "stopw = pd.read_csv('data/stopwords/twitter-stopwords-final.txt').values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', tokenizer=tokenize, stop_words=stopw, min_df=10, ngram_range=(1,4))\n",
    "#vectorizer = TfidfVectorizer(analyzer='word', tokenizer=tokenize, stop_words=stopw)\n",
    "X = vectorizer.fit_transform(tweet_TR.values[:, 0])\n",
    "Y = tweet_TR.values[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 73967)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create the model using svm and feature reduction with 5-fold cross validation\n",
    "def classify(classifier, x_TR, y_TR, x_TE, y_TE):\n",
    "    model = classifier.fit(x_TR, y_TR)  \n",
    "    y_pred = model.predict(x_TE)\n",
    "    return accuracy_score(y_pred, y_TE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classify(LogisticRegression(solver='lbfgs', max_iter=500, random_state=42), x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classify(SGDClassifier(tol=1e-3, max_iter=1000, random_state=42), x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classify(LinearSVC(random_state=42), x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a standard classifier\n",
    "clf = LinearSVC(random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "# Compute the predicitions of x_test\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84185"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the standard model's accuracy (LinearSVC)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find out the best parameters using small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def param_selection(X, Y, nfolds, param_grid, classifier):\n",
    "    \"\"\" Given the features and the predicitons, the number of cross validation,\n",
    "        the parameter grid and the classifier, return the best parameters.\"\"\"\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv = nfolds)\n",
    "    grid_search.fit(X, Y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franckdessimoz/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define the list of parameters to test\n",
    "losses = ['hinge', 'squared_hinge']\n",
    "tols = [1e-5, 1e-4, 1e-3]\n",
    "Cs = [0.1, 1, 10]\n",
    "random_state = [42]\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'loss': losses, 'tol': tols, 'C': Cs, 'random_state': random_state}\n",
    "\n",
    "# Find the best parameters\n",
    "best_parameters = param_selection(x_train, y_train, 5, param_grid, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'loss': 'hinge', 'random_state': 42, 'tol': 1e-05}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the best parameters\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franckdessimoz/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Apply the best parameters\n",
    "tol_opt = best_parameters['tol']\n",
    "C_opt = best_parameters['C']\n",
    "loss_opt = best_parameters['loss']\n",
    "\n",
    "# Create a new classifier with the optimal parameters\n",
    "clf_optimal = LinearSVC(C=C_opt, tol=tol_opt, loss=loss_opt, random_state=42)\n",
    "\n",
    "model = clf_optimal.fit(x_train, y_train)\n",
    "\n",
    "# Compute the predictions of x_test\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8489"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the optimal model's accuracy\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the predictions using optimal parameters on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "tweet_pos, tweet_neg, tweet_test = import_data(full = True)\n",
    "\n",
    "# Construct train set\n",
    "tweet_pos['pred'] = 1\n",
    "tweet_neg['pred'] = 0\n",
    "tweet_pos.columns = ['tweet', 'pred']\n",
    "tweet_neg.columns = ['tweet', 'pred']\n",
    "all_tweets = tweet_neg.append(tweet_pos)\n",
    "tweet_TR = all_tweets.reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "# Construct test set\n",
    "tweet_clean = clean_data(tweet_test.values)\n",
    "np.reshape(tweet_clean, (10000,))\n",
    "tweet_TE = tweet_clean.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', stop_words = stopw, tokenizer=tokenize, ngram_range=(1,4))\n",
    "X = vectorizer.fit_transform(tweet_TR.values[:, 0])\n",
    "Y = tweet_TR.values[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franckdessimoz/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model_optimal = clf_optimal.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.877302"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_optimal.predict(x_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the real predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TE = vectorizer.transform(tweet_TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_TE = model_optimal.predict(X_TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build_submission(y_pred_TE, '16_linearSVC_optimal_3_updated_tokenizer_df_min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
