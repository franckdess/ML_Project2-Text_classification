{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franckdessimoz/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import nltk\n",
    "\n",
    "from textblob import TextBlob, Word\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from tokenizer import tokenizer\n",
    "\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from functions import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "tweet_pos, tweet_neg, tweet_test = import_data(full = False)\n",
    "\n",
    "# Construct train set\n",
    "tweet_pos['pred'] = 1\n",
    "tweet_neg['pred'] = 0\n",
    "tweet_pos.columns = ['tweet', 'pred']\n",
    "tweet_neg.columns = ['tweet', 'pred']\n",
    "all_tweets = tweet_neg.append(tweet_pos)\n",
    "tweet_TR = all_tweets.reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "# Construct test set\n",
    "tweet_clean = clean_data(tweet_test.values)\n",
    "np.reshape(tweet_clean, (10000,))\n",
    "tweet_TE = tweet_clean.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import stopwords\n",
    "#stopw = pd.read_csv('data/stopwords/twitter-stopwords.txt').values.flatten().tolist()\n",
    "stopw = pd.read_csv('data/stopwords/twitter-stopwords - TA - Less.txt').values.flatten().tolist() +\\\n",
    "    pd.read_csv('data/stopwords/twitter-stopwords - TA.txt').values.flatten().tolist() +\\\n",
    "    pd.read_csv('data/stopwords/twitter-stopwords.txt').values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', stop_words = stopw, tokenizer=tokenize, ngram_range=(1,4))\n",
    "X = vectorizer.fit_transform(tweet_TR.values[:, 0])\n",
    "Y = tweet_TR.values[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a standard classifier\n",
    "clf = LinearSVC(random_state=42)\n",
    "clf.fit(x_train, y_train)\n",
    "# Compute the predicitions of x_test\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8535"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the standard model's accuracy (8, 9)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85315"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the standard model's accuracy (1, 4)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find out the best parameters using small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def param_selection(X, Y, nfolds, param_grid, classifier):\n",
    "    \"\"\" Given the features and the predicitons, the number of cross validation,\n",
    "        the parameter grid and the classifier,  return the best parameters.\"\"\"\n",
    "    grid_search = GridSearchCV(classifier, param_grid, cv = nfolds)\n",
    "    grid_search.fit(X, Y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/franckdessimoz/anaconda/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Define the list of parameters to test\n",
    "losses = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "alphas = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]\n",
    "tols = [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "\n",
    "# Create the parameter grid\n",
    "param_grid = {'loss': losses, 'tol': tols, 'alpha': alphas}\n",
    "\n",
    "# Find the best parameters\n",
    "best_parameters = param_selection(x_train, y_train, 5, param_grid, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Print the best parameters\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Apply the best parameters\n",
    "tol_opt = best_parameters['tol']\n",
    "gamma_opt = best_parameters['gamma']\n",
    "loss_opt = best_parameters['loss']\n",
    "\n",
    "# Create a new classifier with the optimal parameters\n",
    "clf_optimal = SGDClassifier(gamma=gamma_opt, tol=tol_opt, loss=loss_opt)\n",
    "model = clf_optimal.fit(x_train, y_train)\n",
    "\n",
    "# Compute the predictions of x_test\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute the optimal model's accuracy\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the predictions using optimal parameters on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "tweet_pos, tweet_neg, tweet_test = import_data(full = True)\n",
    "\n",
    "# Construct train set\n",
    "tweet_pos['pred'] = 1\n",
    "tweet_neg['pred'] = 0\n",
    "tweet_pos.columns = ['tweet', 'pred']\n",
    "tweet_neg.columns = ['tweet', 'pred']\n",
    "all_tweets = tweet_neg.append(tweet_pos)\n",
    "tweet_TR = all_tweets.reset_index().drop(['index'], axis = 1)\n",
    "\n",
    "# Construct test set\n",
    "tweet_clean = clean_data(tweet_test.values)\n",
    "np.reshape(tweet_clean, (10000,))\n",
    "tweet_TE = tweet_clean.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import stopwords\n",
    "#stopw = pd.read_csv('data/stopwords/twitter-stopwords.txt').values.flatten().tolist()\n",
    "stopw = pd.read_csv('data/stopwords/twitter-stopwords - TA - Less.txt').values.flatten().tolist() +\\\n",
    "    pd.read_csv('data/stopwords/twitter-stopwords - TA.txt').values.flatten().tolist() +\\\n",
    "    pd.read_csv('data/stopwords/twitter-stopwords.txt').values.flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(analyzer='word', stop_words = stopw, tokenizer=tokenize, ngram_range=(1,2))\n",
    "X = vectorizer.fit_transform(tweet_TR.values[:, 0])\n",
    "Y = tweet_TR.values[:, 1].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_optimal = clf_optimal.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep track of scores per classifier (small dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84425"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression, small dataset\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8447"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression, small dataset\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep track of scores per classifier (full dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.865242"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.867602"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LinearSVC\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85035"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output the real predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TE = vectorizer.transform(tweet_TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_TE = model_optimal.predict(X_TE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "build_submission(y_pred_TE, '12')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
